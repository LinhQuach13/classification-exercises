{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "# visualize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('figure', figsize=(11, 9))\n",
    "plt.rc('font', size=13)\n",
    "# turn off pink warning boxes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# acquire\n",
    "from env import host, user, password\n",
    "from pydataset import data\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text, export_graphviz\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# docs\n",
    "import acquire\n",
    "import prepare\n",
    "import explore\n",
    "import prepare2\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive: passenger survives\n",
    "# negative: passenger dies\n",
    "# TP: predict survival, and the passenger actually survived\n",
    "# TN: predict death, and passenger actually died\n",
    "# FN: predict death, but passenger actually survived\n",
    "# FP: predict survival, but passenger actually died"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What is your baseline prediction? What is your baseline accuracy? \n",
    "# remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). \n",
    "# When you make those predictions, what is your accuracy? This is your baseline accuracy.\n",
    "#Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:\n",
    "\n",
    "train, validate, test = prepare2.prep_titanic_data(acquire.get_titanic_data(), column = 'age', method = 'median', dummies = ['embarked', 'sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 12), (214, 12), (179, 12))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape # looking at shape for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting ready to test models\n",
    "X_train, y_train = train.drop(columns='survived'), train.survived\n",
    "X_validate, y_validate = validate.drop(columns='survived'), validate.survived\n",
    "X_test, y_test = test.drop(columns='survived'), test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['survived'].value_counts() #Looking at most common value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.6165\n"
     ]
    }
   ],
   "source": [
    "# baseline prediction = 0 (everyone dies)\n",
    "\n",
    "# 1. Create the object\n",
    "baseline = DummyClassifier(strategy='constant', constant=0)\n",
    "# 2. Fit the object\n",
    "baseline.fit(X_train, y_train)\n",
    "# how does it do on training data set?\n",
    "print('Training accuracy: %.4f' % baseline.score(X_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>First</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>Third</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>Third</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Second</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>First</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass   age  sibsp  parch      fare   class  \\\n",
       "583           583         0       1  36.0      0      0   40.1250   First   \n",
       "165           165         1       3   9.0      0      2   20.5250   Third   \n",
       "50             50         0       3   7.0      4      1   39.6875   Third   \n",
       "259           259         1       2  50.0      0      1   26.0000  Second   \n",
       "306           306         1       1  28.0      0      0  110.8833   First   \n",
       "\n",
       "     alone  embarked_Q  embarked_S  sex_male  \n",
       "583      1           0           0         1  \n",
       "165      0           0           1         1  \n",
       "50       0           0           1         1  \n",
       "259      0           0           1         0  \n",
       "306      1           0           0         0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = ['pclass', 'alone', 'embarked_Q', 'embarked_S', 'sex_male']\n",
    "y_col = 'survived'\n",
    "\n",
    "X_train, y_train = train[X_cols], train[y_col]\n",
    "X_validate, y_validate = validate[X_cols], validate[y_col]\n",
    "X_test, y_test = test[X_cols], test[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can drop columns instead of calling specific columns like above, commented out so won't run\n",
    "\n",
    "# train.drop(columns = 'class', inplace=True)\n",
    "# validate.drop(columns = 'class', inplace=True)\n",
    "# test.drop(columns = 'class', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 81.93%\n",
      "validate score: 79.44%\n"
     ]
    }
   ],
   "source": [
    "#Model 1 score\n",
    "print(f'training score: {tree.score(X_train, y_train):.2%}')\n",
    "print(f'validate score: {tree.score(X_validate, y_validate):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['prediction'] = tree.predict(X_train) # prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>First</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>Third</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>Third</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Second</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>First</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass   age  sibsp  parch      fare   class  \\\n",
       "583           583         0       1  36.0      0      0   40.1250   First   \n",
       "165           165         1       3   9.0      0      2   20.5250   Third   \n",
       "50             50         0       3   7.0      4      1   39.6875   Third   \n",
       "259           259         1       2  50.0      0      1   26.0000  Second   \n",
       "306           306         1       1  28.0      0      0  110.8833   First   \n",
       "\n",
       "     alone  embarked_Q  embarked_S  sex_male  prediction  \n",
       "583      1           0           0         1           0  \n",
       "165      0           0           1         1           0  \n",
       "50       0           0           1         1           0  \n",
       "259      0           0           1         0           1  \n",
       "306      1           0           0         0           1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_features=4)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding parameters to model above\n",
    "tree2 = DecisionTreeClassifier(max_features=4)\n",
    "tree2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 81.93%\n",
      "validate score: 79.44%\n"
     ]
    }
   ],
   "source": [
    "#Model 2 score\n",
    "print(f'training score: {tree2.score(X_train, y_train):.2%}')\n",
    "print(f'validate score: {tree2.score(X_validate, y_validate):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 81.93%\n",
      "validate score: 79.44%\n"
     ]
    }
   ],
   "source": [
    "#Model 1 score\n",
    "print(f'training score: {tree.score(X_train, y_train):.2%}')\n",
    "print(f'validate score: {tree.score(X_validate, y_validate):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    371\n",
       "1    127\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.prediction.value_counts() # looking at unique values for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.survived.value_counts() # looking at unique values for survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[294,  13],\n",
       "       [ 77, 114]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(train.survived, train.prediction) #Looking at confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Confusion Matrix\n",
    "- train.survived= row totals\n",
    "- train.prediction= column totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred death</th>\n",
       "      <th>pred survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual death</th>\n",
       "      <td>294</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual survived</th>\n",
       "      <td>77</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred death  pred survived\n",
       "actual death            294             13\n",
       "actual survived          77            114"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Putting confusion matrix into dataframe\n",
    "pd.DataFrame(confusion_matrix(train.survived, train.prediction), index=['actual death', 'actual survived'], columns=['pred death', 'pred survived'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification report\n",
    "classification = pd.DataFrame(classification_report(train.survived, train.prediction, output_dict= True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.897638</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.845045</td>\n",
       "      <td>0.832795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.957655</td>\n",
       "      <td>0.596859</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.777257</td>\n",
       "      <td>0.819277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.867257</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.792119</td>\n",
       "      <td>0.809621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.792453    0.897638  0.819277    0.845045      0.832795\n",
       "recall       0.957655    0.596859  0.819277    0.777257      0.819277\n",
       "f1-score     0.867257    0.716981  0.819277    0.792119      0.809621\n",
       "support    307.000000  191.000000  0.819277  498.000000    498.000000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 1 is survived and 0 is not survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "#Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive: passenger survives\n",
    "# negative: passenger dies\n",
    "# TP: predict survival, and the passenger actually survived\n",
    "# TN: predict death, and passenger actually died\n",
    "# FN: predict death, but passenger actually survived\n",
    "# FP: predict survival, but passenger actually died"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = pd.DataFrame(classification_report(train.survived, train.prediction, output_dict= True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.897638</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.845045</td>\n",
       "      <td>0.832795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.957655</td>\n",
       "      <td>0.596859</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.777257</td>\n",
       "      <td>0.819277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.867257</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.792119</td>\n",
       "      <td>0.809621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.792453    0.897638  0.819277    0.845045      0.832795\n",
       "recall       0.957655    0.596859  0.819277    0.777257      0.819277\n",
       "f1-score     0.867257    0.716981  0.819277    0.792119      0.809621\n",
       "support    307.000000  191.000000  0.819277  498.000000    498.000000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification= classification.rename(columns={'0': \"dead\", '1': \"survived\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dead</th>\n",
       "      <th>survived</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.897638</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.845045</td>\n",
       "      <td>0.832795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.957655</td>\n",
       "      <td>0.596859</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.777257</td>\n",
       "      <td>0.819277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.867257</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.792119</td>\n",
       "      <td>0.809621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dead    survived  accuracy   macro avg  weighted avg\n",
       "precision    0.792453    0.897638  0.819277    0.845045      0.832795\n",
       "recall       0.957655    0.596859  0.819277    0.777257      0.819277\n",
       "f1-score     0.867257    0.716981  0.819277    0.792119      0.809621\n",
       "support    307.000000  191.000000  0.819277  498.000000    498.000000"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification #Verifying column renamed were changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN= 294\n",
    "FN= 77\n",
    "FP= 13\n",
    "TP= 114\n",
    "\n",
    "tpr = TP/(TP+FN)\n",
    "fpr = FP/(FP+TN)\n",
    "tnr = TN/(TN+FP)\n",
    "fnr = FN/(FN+TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5968586387434555"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#True positive rate\n",
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04234527687296417"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#False positive rate\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9576547231270358"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True negative rate\n",
    "tnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4031413612565445"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False negative rate\n",
    "fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive: passenger survives\n",
    "# negative: passenger dies\n",
    "# TP: predict survival, and the passenger actually survived\n",
    "# TN: predict death, and passenger actually died\n",
    "# FN: predict death, but passenger actually survived\n",
    "# FP: predict survival, but passenger actually died"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Run through steps 2-4 using a different max_depth value.\n",
    "def run_metrics(model, data_set):\n",
    "    \"\"\"\n",
    "    This function takes in a model and ouputs metrics. \n",
    "    model = name of class model\n",
    "    data_set = train, validate, test (AS A STRING)\n",
    "    Will output the Precision Score, the classification report, and the confusion matrix\n",
    "    It is advisable to print the name of the model you're working with before hand for clarity\n",
    "    i.e. print('Metrics for Model 1 with Train data\\n')\n",
    "    \"\"\"\n",
    "    if data_set == 'train':\n",
    "        X = X_train\n",
    "        y = y_train\n",
    "        df = train\n",
    "    if data_set == 'validate':\n",
    "        X = X_validate\n",
    "        y = y_validate\n",
    "        df = validate\n",
    "    if data_set == 'test':\n",
    "        X = X_test\n",
    "        y = y_test\n",
    "        df = test\n",
    "    score = model.score(X, y)\n",
    "    matrix = confusion_matrix(y, model.predict(X))\n",
    "    tpr = matrix[1,1] / (matrix[1,1] + matrix[1,0])\n",
    "    fpr = matrix[0,1] / (matrix[0,1] + matrix[0,0])\n",
    "    tnr = matrix[0,0] / (matrix[0,0] + matrix[0,1])\n",
    "    fnr = matrix[1,0] / (matrix[1,1] + matrix[1,0])\n",
    "    print(f'{data_set} data set accuracy score: {score:.2%}')\n",
    "    class_report = classification_report(y, model.predict(X), zero_division=True)\n",
    "    print('-------------------------------')\n",
    "    print(f'classification report')\n",
    "    print(class_report)\n",
    "    print ('-------------------------------')\n",
    "    print('')\n",
    "    print('confusion matrix')\n",
    "    print(matrix)\n",
    "    print(' ')\n",
    "    print(f'{data_set} data set model metrics')\n",
    "    print('---------------------------------')\n",
    "    print(f'True positive rate for the model is {tpr:.2%}')\n",
    "    print(f'False positive rate for the model is  {fpr:.2%}')\n",
    "    print(f'True negative rate for the model is {tnr:.2%}')\n",
    "    print(f'False negative rate for the model is {fnr:.2%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_features=3)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding parameters to model above\n",
    "tree3 = DecisionTreeClassifier(max_features=3)\n",
    "tree3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 81.93%\n",
      "validate score: 79.44%\n"
     ]
    }
   ],
   "source": [
    "#Model 3 score\n",
    "print(f'training score: {tree3.score(X_train, y_train):.2%}')\n",
    "print(f'validate score: {tree3.score(X_validate, y_validate):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data set accuracy score: 81.93%\n",
      "-------------------------------\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87       307\n",
      "           1       0.90      0.60      0.72       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.85      0.78      0.79       498\n",
      "weighted avg       0.83      0.82      0.81       498\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "confusion matrix\n",
      "[[294  13]\n",
      " [ 77 114]]\n",
      " \n",
      "train data set model metrics\n",
      "---------------------------------\n",
      "True positive rate for the model is 59.69%\n",
      "False positive rate for the model is  4.23%\n",
      "True negative rate for the model is 95.77%\n",
      "False negative rate for the model is 40.31%\n"
     ]
    }
   ],
   "source": [
    "run_metrics(tree3, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate data set accuracy score: 79.44%\n",
      "-------------------------------\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85       132\n",
      "           1       0.88      0.54      0.67        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.82      0.75      0.76       214\n",
      "weighted avg       0.81      0.79      0.78       214\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "confusion matrix\n",
      "[[126   6]\n",
      " [ 38  44]]\n",
      " \n",
      "validate data set model metrics\n",
      "---------------------------------\n",
      "True positive rate for the model is 53.66%\n",
      "False positive rate for the model is  4.55%\n",
      "True negative rate for the model is 95.45%\n",
      "False negative rate for the model is 46.34%\n"
     ]
    }
   ],
   "source": [
    "run_metrics(tree3, \"validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_features=5)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree4 = DecisionTreeClassifier(max_features=5)\n",
    "tree4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data set accuracy score: 81.93%\n",
      "-------------------------------\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87       307\n",
      "           1       0.90      0.60      0.72       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.85      0.78      0.79       498\n",
      "weighted avg       0.83      0.82      0.81       498\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "confusion matrix\n",
      "[[294  13]\n",
      " [ 77 114]]\n",
      " \n",
      "train data set model metrics\n",
      "---------------------------------\n",
      "True positive rate for the model is 59.69%\n",
      "False positive rate for the model is  4.23%\n",
      "True negative rate for the model is 95.77%\n",
      "False negative rate for the model is 40.31%\n"
     ]
    }
   ],
   "source": [
    "run_metrics(tree4, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate data set accuracy score: 79.44%\n",
      "-------------------------------\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85       132\n",
      "           1       0.88      0.54      0.67        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.82      0.75      0.76       214\n",
      "weighted avg       0.81      0.79      0.78       214\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "confusion matrix\n",
      "[[126   6]\n",
      " [ 38  44]]\n",
      " \n",
      "validate data set model metrics\n",
      "---------------------------------\n",
      "True positive rate for the model is 53.66%\n",
      "False positive rate for the model is  4.55%\n",
      "True negative rate for the model is 95.45%\n",
      "False negative rate for the model is 46.34%\n"
     ]
    }
   ],
   "source": [
    "run_metrics(tree4, \"validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Which model performs better on your in-sample data?\n",
    "\n",
    "#Answer they all performed very similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Which model performs best on your out-of-sample data, the validate set?\n",
    "\n",
    "#Answer they all performed very similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercises\n",
    "# Continue working in your model file with titanic data to do the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rf_prediction'] = rf.predict(X_train) # prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>prediction</th>\n",
       "      <th>rf_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>First</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>Third</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>Third</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Second</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>First</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass   age  sibsp  parch      fare   class  \\\n",
       "583           583         0       1  36.0      0      0   40.1250   First   \n",
       "165           165         1       3   9.0      0      2   20.5250   Third   \n",
       "50             50         0       3   7.0      4      1   39.6875   Third   \n",
       "259           259         1       2  50.0      0      1   26.0000  Second   \n",
       "306           306         1       1  28.0      0      0  110.8833   First   \n",
       "\n",
       "     alone  embarked_Q  embarked_S  sex_male  prediction  rf_prediction  \n",
       "583      1           0           0         1           0              0  \n",
       "165      0           0           1         1           0              0  \n",
       "50       0           0           1         1           0              0  \n",
       "259      0           0           1         0           1              1  \n",
       "306      1           0           0         0           1              1  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 81.93%\n",
      "validate score: 79.44%\n"
     ]
    }
   ],
   "source": [
    "#rf Model 1 score\n",
    "print(f'training score: {rf.score(X_train, y_train):.2%}')\n",
    "print(f'validate score: {rf.score(X_validate, y_validate):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "# 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data set accuracy score: 81.93%\n",
      "-------------------------------\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87       307\n",
      "           1       0.90      0.60      0.72       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.85      0.78      0.79       498\n",
      "weighted avg       0.83      0.82      0.81       498\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "confusion matrix\n",
      "[[294  13]\n",
      " [ 77 114]]\n",
      " \n",
      "train data set model metrics\n",
      "---------------------------------\n",
      "True positive rate for the model is 59.69%\n",
      "False positive rate for the model is  4.23%\n",
      "True negative rate for the model is 95.77%\n",
      "False negative rate for the model is 40.31%\n"
     ]
    }
   ],
   "source": [
    "run_metrics(rf, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate data set accuracy score: 79.44%\n",
      "-------------------------------\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85       132\n",
      "           1       0.88      0.54      0.67        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.82      0.75      0.76       214\n",
      "weighted avg       0.81      0.79      0.78       214\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "confusion matrix\n",
      "[[126   6]\n",
      " [ 38  44]]\n",
      " \n",
      "validate data set model metrics\n",
      "---------------------------------\n",
      "True positive rate for the model is 53.66%\n",
      "False positive rate for the model is  4.55%\n",
      "True negative rate for the model is 95.45%\n",
      "False negative rate for the model is 46.34%\n"
     ]
    }
   ],
   "source": [
    "run_metrics(rf, \"validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "rf2 = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=10,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=60, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=60, min_samples_leaf=10, random_state=123)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data set accuracy score: 81.93%\n",
      "-------------------------------\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87       307\n",
      "           1       0.90      0.60      0.72       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.85      0.78      0.79       498\n",
      "weighted avg       0.83      0.82      0.81       498\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "confusion matrix\n",
      "[[294  13]\n",
      " [ 77 114]]\n",
      " \n",
      "train data set model metrics\n",
      "---------------------------------\n",
      "True positive rate for the model is 59.69%\n",
      "False positive rate for the model is  4.23%\n",
      "True negative rate for the model is 95.77%\n",
      "False negative rate for the model is 40.31%\n"
     ]
    }
   ],
   "source": [
    "run_metrics(rf2, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate data set accuracy score: 79.44%\n",
      "-------------------------------\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85       132\n",
      "           1       0.88      0.54      0.67        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.82      0.75      0.76       214\n",
      "weighted avg       0.81      0.79      0.78       214\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "confusion matrix\n",
      "[[126   6]\n",
      " [ 38  44]]\n",
      " \n",
      "validate data set model metrics\n",
      "---------------------------------\n",
      "True positive rate for the model is 53.66%\n",
      "False positive rate for the model is  4.55%\n",
      "True negative rate for the model is 95.45%\n",
      "False negative rate for the model is 46.34%\n"
     ]
    }
   ],
   "source": [
    "run_metrics(rf2, \"validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3 = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=60,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=100, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=100, min_samples_leaf=60, random_state=123)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data set accuracy score: 79.52%\n",
      "-------------------------------\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.85       307\n",
      "           1       0.92      0.51      0.66       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.84      0.74      0.76       498\n",
      "weighted avg       0.82      0.80      0.78       498\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "confusion matrix\n",
      "[[298   9]\n",
      " [ 93  98]]\n",
      " \n",
      "train data set model metrics\n",
      "---------------------------------\n",
      "True positive rate for the model is 51.31%\n",
      "False positive rate for the model is  2.93%\n",
      "True negative rate for the model is 97.07%\n",
      "False negative rate for the model is 48.69%\n"
     ]
    }
   ],
   "source": [
    "run_metrics(rf3, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate data set accuracy score: 78.50%\n",
      "-------------------------------\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85       132\n",
      "           1       0.89      0.50      0.64        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.82      0.73      0.74       214\n",
      "weighted avg       0.81      0.79      0.77       214\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "confusion matrix\n",
      "[[127   5]\n",
      " [ 41  41]]\n",
      " \n",
      "validate data set model metrics\n",
      "---------------------------------\n",
      "True positive rate for the model is 50.00%\n",
      "False positive rate for the model is  3.79%\n",
      "True negative rate for the model is 96.21%\n",
      "False negative rate for the model is 50.00%\n"
     ]
    }
   ],
   "source": [
    "run_metrics(rf3, \"validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "#Answer: There is not very much difference in the metrics. The first random tree model (rf) performed better on the in-sample data possibly due to sample being smaller max_depth and larger min_sample_leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After making a few models, which one has the best performance (or closest metrics) on both train and validate?\n",
    "#Answer: The model that had the closest metrics on both train and validate was the last model (rf3) which had an increase in min_sample_leaf and max_depth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
